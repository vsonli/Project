1 实现功能
这个项目是用来根据用户id爬取微博用户信息的数据，并写入sqlite数据库。
而这个用户id是在微博签到页爬虫这个爬虫项目生成的weibo.sqlite数据库中读取的。（需要把微博签到页的weibo.sqlite文件拷贝到该项目目录）
所以想要爬自己有的一串用户id的数据的朋友，可能还需要在这个小爬虫上面再改改。以及这个爬虫是需要自己微博登录的cookie的。
2 依赖环境
需要额外的第三方库有yagmail（用来发送邮件）,pandas，bs4, numpy。均可使用pip来安装。
pip install yagmail pandas bs4 numpy
3 使用方法
step1. 修改cookie.txt中的cookie改为自己微博登录的cookie。（如何获取还请额外百度，非常多教程！）
step2. 修改代码中的邮箱账号密码以及数据库路径。
step3. Run！
4 文件说明
包含两个文件。
cookie.txt
就是用来存放cookie的。
WeiboUserInfo.py
爬虫本体。